{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis\n",
    "_**HARD: This is a curveball assignment. Plus, this is Python without Pandas.**_\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports `os` as a dependency because the `os.path.join` function. Also, the `string` dependency is needed because later in the script, `string.punctuation` will be used to detect and remove punctuation symbols. Explain what the line `from collection import Counter` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[Replace this with your clear explanation of what happens in the cell below. Think about how the `REQUIRED_SKILLS` set and the `DESIRED_SKILLS` set can be used in the program. Also, why are the variables in ALL CAPS?]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Assigning a variable to our path for easy reference\n",
    "# 4 Dictionaries in all caps to give a visual clues to be acknowledged as a Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resume_path = os.path.join(\".\", 'resume.md')\n",
    "\n",
    "# Skills to match\n",
    "REQUIRED_SKILLS = {\"excel\", \"python\", \"mysql\", \"statistics\"}\n",
    "DESIRED_SKILLS = {\"r\", \"git\", \"html\", \"css\", \"leaflet\", \"modeling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[Replace this with your clear explanation of what happens in the cell below. How is this function defined? What does it take in, how does it work, and what does it return?]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Defining \"load_file\" and what it should do to the selected (\"filepath\")\n",
    "# 3 first part of the loop is opening the file and reading it, moving forward to the next step\n",
    "# 4 Once again read the file, and while reading change the file to lower case as specified in the command '.lower'\n",
    "# 5 split the words up to become searchable as \"tokens\"\n",
    "# 7 Return the newly formated words in the filepath as searchable values or \"tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    # Helper function to read a file and return the data.\n",
    "    with open(filepath, \"r\") as resume_file_handler:\n",
    "        resume_contents = resume_file_handler.read()\n",
    "        resume_contents = resume_contents.lower()\n",
    "        resume_tokens = resume_contents.split()\n",
    "        return resume_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[Replace this with your clear explanation of what happens in the cell below. What is this cell doing? Is it passing anything? Does it get anything back? What happens to `word_list`?]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the resume file as a \"word_list\" to automate processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text for a Resume\n",
    "word_list = load_file(resume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. \n",
    "Be sure to answer the following:\n",
    "* Why is a `set` created?\n",
    "* How are we populating the set\n",
    "* Why would it be necessary to create a `punctuation` set?\n",
    "* What does subtracting from the set do?\n",
    "* * Refer to the `resume = resume - punctuation` line\n",
    "* What does `\\n` do in a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1  We are creating a place holder or a set to hold our returned values and no duplicates!\n",
    "# 4  We are now starting a loop to comb through our tokens that we cleaned up and lower cased \n",
    "#    through our variable \"word_list\" and populating our set\n",
    "# 8  printing our list out before changes with a nice little Header\n",
    "# 11 We are now making a punctuation set to get each unique punctuation value to later be able to subtract \n",
    "#    quickly by referencing the set.\n",
    "# 14  Subtract the punctuation set from the resume to remove all unwanted characters\n",
    "# 16  Print the new Header and resume, cleaned up!  \"\\n\" signafies to add a New Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORDS BEFORE MOVING PUNCTUATION\n",
      "{'to', 'tables', 'the', 'apis.', 'with', 'excel,', 'pandas', 'n.', 'learning,', 'microsoft', 'html,', 'advanced', 'visualization', 'writing', 'using', 'stein', 'working', 'sets', 'modeling', 'contributing', 'machine', 'analyze', 'vba', 'r,', 'hadoop,', 'web', 'cloud', 'mongodb', 'and', 'pivot', 'api', 'visualizations', 'designing', 'data', 'leaflet.js', 'graduate', 'aws', 'basic', 'mining,', 'javascript,', 'apps', 'from', 'statistics', 'forecasting', 'in', 'tableau', 'excel.', 'files', 'open-source', 'git/github', 'boot', 'learning', 'experience', 'interests', 'frank', 'education', 'html/css,', 'mysql', 'performing', 'creating', 'python', 'databases', 'bootstrap,', 'd3,', '*', 'sql,', 'business', '##', 'algorithms', 'social', 'media', '#', 'camp', 'software', 'big', 'skills', 'hadoop', 'interactions,', 'python,', 'front-end', 'analytics', 'developing', 'tableau,', 'css,', 'd3', 'scripts', 'mining', 'statistics,', 'intelligence'}\n",
      "\n",
      "WORDS AFTER MOVING PUNCTUATION\n",
      "{'to', 'tables', 'the', 'apis.', 'with', 'excel,', 'pandas', 'n.', 'learning,', 'microsoft', 'html,', 'advanced', 'writing', 'visualization', 'using', 'stein', 'working', 'sets', 'modeling', 'statistics,', 'contributing', 'machine', 'analyze', 'vba', 'r,', 'hadoop,', 'web', 'cloud', 'mongodb', 'and', 'pivot', 'api', 'visualizations', 'designing', 'data', 'leaflet.js', 'graduate', 'aws', 'basic', 'mining,', 'javascript,', 'apps', 'from', 'statistics', 'forecasting', 'in', 'tableau', 'excel.', 'files', 'open-source', 'git/github', 'boot', 'learning', 'experience', 'interests', 'frank', 'education', 'html/css,', 'mysql', 'performing', 'creating', 'databases', 'bootstrap,', 'd3,', 'sql,', 'business', '##', 'algorithms', 'media', 'social', 'camp', 'software', 'big', 'skills', 'hadoop', 'interactions,', 'python,', 'front-end', 'analytics', 'developing', 'tableau,', 'css,', 'd3', 'scripts', 'mining', 'python', 'intelligence'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words from the resume\n",
    "resume = set()\n",
    "\n",
    "# HINT: Single elements in a programming language are often referred to as tokens\n",
    "for token in word_list:\n",
    "    resume.add(token)\n",
    "\n",
    "print('\\nWORDS BEFORE MOVING PUNCTUATION')    \n",
    "print(resume)\n",
    "\n",
    "# Remove Punctuation that were read as whole words\n",
    "punctuation = set(string.punctuation)\n",
    "# HINT: Attributes that are in `resume` that are not in `punctuation` (difference)\n",
    "resume = resume - punctuation\n",
    "\n",
    "print('\\nWORDS AFTER MOVING PUNCTUATION')    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. \n",
    "Be sure to answer the following:\n",
    "* What does using a `set` intersection do in this section?\n",
    "* How does the character cleaning function work differently than the word cleaning function? (test it)\n",
    "* Can you add more items to the `stop_words` list?\n",
    "* Explain how the list `word_list` list comprehension works. What does it return and what is the filtering criteria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Print Title Required skills, and also search the resume and reutrn any similar values that appear in the \n",
    "#   \"REQUIRED_SKILLS\" set\n",
    "# 5 Do the same as above for \"DESIRED_SKILLS\"\n",
    "#   This is a set intersection, and returns only the values that are similar in the two sets\n",
    "# 10 Word_list scans each word for other characters other than what was in the punctuation list\n",
    "# 15 Character cleaning then takes the word cleaning a step further by looping through each individual character \n",
    "#    In the word_list and further cleaning out the symbols and characters that are not needed\n",
    "# 20 Cleaning the stop words, removes the list of stop_words determined. Making the resume more factual, and \n",
    "#    removing the words without much \"value\" to the job search. More words are able to be added to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED SKILLS\n",
      "{'mysql', 'python', 'statistics'}\n",
      "DESIRED SKILLS\n",
      "{'modeling'}\n",
      "\n",
      "WORD LIST AFTER PUNCTUATION REMOVAL\n",
      "['frank', 'n.', 'stein', '##', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '##', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel.', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis.', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'front-end', 'web', 'visualizations', 'using', 'html,', 'css,', 'bootstrap,', 'd3,', 'and', 'leaflet.js', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '##', 'skills', 'microsoft', 'excel,', 'python,', 'javascript,', 'html/css,', 'api', 'interactions,', 'social', 'media', 'mining,', 'sql,', 'hadoop,', 'tableau,', 'advanced', 'statistics,', 'machine', 'learning,', 'r,', 'git/github', '##', 'interests', 'contributing', 'to', 'open-source', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html,', 'css,', 'javascript,', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER CHARACTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'using', 'html', 'css', 'bootstrap', 'd3', 'and', 'leafletjs', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'to', 'opensource', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html', 'css', 'javascript', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER STOP WORDS\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Required Skills Match using Set Intersection\n",
    "print('REQUIRED SKILLS')\n",
    "print(resume & REQUIRED_SKILLS)\n",
    "\n",
    "# Calculate the Desired Skills Match using Set Intersection\n",
    "print('DESIRED SKILLS')\n",
    "print(resume & DESIRED_SKILLS)\n",
    "\n",
    "\n",
    "# Word Punctuation Cleaning\n",
    "word_list = [word for word in word_list if word not in string.punctuation]\n",
    "print('\\nWORD LIST AFTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Character Punctuation Cleaning\n",
    "word_list = [''.join(char for char in word if char not in string.punctuation) for word in word_list]\n",
    "print('\\nWORD LIST AFTER CHARACTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Clean Stop Words\n",
    "stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\"]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "print('\\nWORD LIST AFTER STOP WORDS')\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below.\n",
    "Be sure to explain the following:\n",
    "\n",
    "* How was the `word_count` dictionary initialized, what were in initial key values, and how were they set?\n",
    "* Explain the logic behind incrementing the world count value using the `for loop`. Be sure to explain how to reference the word key in the `word_count` dictionary\n",
    "* Collections.counter is optional, but explain the difference between the `for loop` and using `Counter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 The word_count dictionary is initialized by setting the variable here. The intial value is 0\n",
    "#   This acts as a place holder demonstrated by the curly braces {}, and the count being at 0 for the word_list\n",
    "# 6 Begine the for loop. cycling through words, in the word_list. For each count in word_count, we are going to \n",
    "#   add a value equal to one to our word_list\n",
    "# 12 word_counter can be used, and is a much simpler function, pulled in by our imported module. It can also be\n",
    "#    used to determine frequency of used words, not just the overall count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Top 10 Words\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# Resume Word Count\n",
    "# ==========================\n",
    "# Initialize a dictionary with default values equal to zero\n",
    "word_count = {}.fromkeys(word_list, 0)\n",
    "\n",
    "# Loop through the word list and count each word.\n",
    "for word in word_list:\n",
    "    word_count[word] += 1\n",
    "# print(word_count)\n",
    "\n",
    "# Bonus using collections.Counter\n",
    "word_counter = Counter(word_list)\n",
    "# print(word_counter)\n",
    "\n",
    "# Comparing both word count solutions\n",
    "print(word_count == word_counter)\n",
    "\n",
    "# Top 10 Words\n",
    "print(\"Top 10 Words\")\n",
    "print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. Which column was sorted and how? How was the top ten selected? Does that explain the significance of `[:10]`?\n",
    "\n",
    "As a bonus, explain how you would get rid of the blank token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Sorted words give you the unique \"tokens\" that you cleaned up\n",
    "# 3 Now, in line 3, we are cycling through the words, up to index 10, most popular, to return to the top \n",
    "#   ten most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort words by count and print the top 10\n",
    "sorted_words = []\n",
    "for word in sorted(word_count, key=word_count.get, reverse=True)[:10]:\n",
    "    print(f\"Token: {word:20} Count: {word_count[word]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
